{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration by making author indexes from paper information\n",
    "\n",
    "This Jupyter Notebook is used to give a demonstration of the creation of author indexes of 3 conference proceedings from author information using regular expression and LaTeX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement\n",
    "\n",
    "The author index should contain a list of author names with the paper numbers of their papers they wrote. Since there are three different categories of papers, there should be three author indexes. Note that all author indexes should be in the same format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "\n",
    "There is a few procedure that we will go through to create the author indexes of three different categories of papers from raw text data of the conference prcoceedings like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿R-01: Evaluating Alternative Refrigerants & Technologies\n",
      "Time: Monday, 14/Jul/2014: 1:00pm - 3:00pm  •  Location: 214 A&B\n",
      "ID: 2175\n",
      "R-404A Alternative Refrigerant with Low Compressor Discharge Temperature\n",
      "Barbara Minor1, Vladimir Sulc2, Jeff Berge3, Michal Kolda4, Michal Hegar5\n",
      "1DuPont Fluoroproducts; 2Thermo King, Corp, Ingersoll Rand; 3Thermo King, Corp, Ingersoll Rand; 4Ingersoll Rand Equipment Manufacturing; 5Ingersoll Rand Equipment Manufacturing; barbara.h.minor@dupont.com\n",
      "\n",
      "ID: 2250\n",
      "AHRI Low Global Warming Potential Alternative Refrigerants Evaluation Program (Low-GWP AREP) – Summary of Phase I Testing Results\n",
      "Xudong Wang, Karim Amrane\n"
     ]
    }
   ],
   "source": [
    "with open('conference_session_paper.txt') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline()[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the procedures are\n",
    "\n",
    "* Extract the author names and paper numbers\n",
    "* Order the data\n",
    "* Put the information and the links in the LaTeX template\n",
    "* Compile the author indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and organizing the data\n",
    "\n",
    "Let's start the demo by opening the files to import the data. We have two data files to import\n",
    "\n",
    "* __conference\\_session\\_paper.txt__ which contains the conference paper data\n",
    "* __double_name.txt__ which contains which last names contain more than one word such as 'van der Bor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open read file\n",
    "main_name = 'conference_session_paper.txt'\n",
    "fread = open(main_name, 'r')  # read only\n",
    "\n",
    "# find the names which have double family names and add an identifier to them\n",
    "fname = open('double_name.txt')\n",
    "fname.readline()\n",
    "double_name = []\n",
    "name = fname.readline().split('\\n')[0]  # and arrange the names in an array\n",
    "while name != '':\n",
    "    double_name.append(name)\n",
    "    name = fname.readline().split('\\n')[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's prepare the files to store the data of papers of three different cateogires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open write files\n",
    "filename = []\n",
    "file_declar = []\n",
    "filename.append('author_index_raw_comp.txt')\n",
    "filename.append('author_index_raw_refri.txt')\n",
    "filename.append('author_index_raw_building.txt')\n",
    "for name in filename:\n",
    "    file_declar.append(open(name, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's extract the data from the _conference_session_paper.txt_ and write the author names and paper numbers into separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# identify text and write appropriate lines\n",
    "text_line = fread.readline()  # read one line\n",
    "while text_line != '':   # not end of file\n",
    "    # check if it has read an id number\n",
    "    if text_line[0:3] == 'The':\n",
    "        # withdrawn papers, skip to the next line\n",
    "        text_line = fread.readline()\n",
    "    elif text_line[0:3] == 'ID:':\n",
    "        id_num = text_line[4:8]\n",
    "        # set filewriter\n",
    "        fwrite = file_declar[int(id_num[0])-1]\n",
    "        fread.readline()  # ignore the paper title line\n",
    "        author_list = re.split(\n",
    "            '[0-9],[0-9], |[0-9], |, |,|[0-9]\\n|[0-9]|[0-9],|\\n|',\n",
    "            fread.readline()\n",
    "        )  # form an author list\n",
    "        # check for multiple words in family name first\n",
    "        # print author_list\n",
    "        for person in author_list:  # for each author\n",
    "            for dbname in double_name:\n",
    "                if person.find(dbname):\n",
    "                    person = person.replace(\n",
    "                        dbname, dbname.replace(' ', '_')\n",
    "                    )\n",
    "            name = person.split(' ')\n",
    "            if name[0] != '':  # only write if a string is observed\n",
    "                word = len(name)\n",
    "                fwrite.write(name[word-1]+', ')  # write last name first\n",
    "                for char in range(word-1):\n",
    "                    fwrite.write(name[char]+' ')\n",
    "                    # write the corresponding id number with an indicator\n",
    "                fwrite.write(':'+id_num+'\\n')\n",
    "        # reset file writer\n",
    "        file_declar[int(id_num[0])-1] = fwrite\n",
    "    text_line = fread.readline()  # read another line\n",
    "\n",
    "# close files\n",
    "fread.close()\n",
    "for declar in file_declar:\n",
    "    declar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of __regular expression__ _'[0-9],[0-9], |[0-9], |, |,|[0-9]\\n|[0-9]|[0-9],|\\n|'_ to get the names only from the line with author data, such as\n",
    "\n",
    "* Barbara Minor1, Vladimir Sulc2, Jeff Berge3, Michal Kolda4, Michal Hegar5\n",
    "* Stephen Anthony Kujak, Panayu Robert Srichai, Kenneth J. Schultz\n",
    "* Noriaki Ishii1, Takuma Tsuji2, Keiko Anami3, Charles W. Knisely4, Tatsuya Oku2, Koichi Nokiyama1, Kiyoshi Sawai5, Hirofumi Yoshida6, Hiroaki Nakai6\n",
    "\n",
    "Without the regular expression, you may need to write many more lines to extract the names from the line of information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertagnolio, Stephane :1627\n",
      "Winandy, Eric :1627\n",
      "Vazquez, Sonia :1627\n",
      "Gao, Haiyang :1425\n",
      "Fukuta, Mitsuhiro :1255\n",
      "Ogi, Daisuke :1255\n",
      "Motozawa, Masaaki :1255\n",
      "Yanagisawa, Tadashi :1255\n",
      "Iwanami, Shigeki :1255\n",
      "Hotta, Tadashi :1255\n"
     ]
    }
   ],
   "source": [
    "with open('author_index_raw_comp.txt') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline()[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two problems:\n",
    "\n",
    "* The data are not ordered\n",
    "* Only one paper is assigned to each author\n",
    "\n",
    "and we need to fix that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order the author names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordering can be done by opening the files, order the rows according to the characters and put the data back into the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after writing the initial file, read for sorting and write again\n",
    "for name in filename:\n",
    "    fread = open(name, 'r')\n",
    "    raw = sorted(str.split(fread.read(), '\\n'), key=str.lower)  # where the ordering is done\n",
    "    fread.close()\n",
    "    fwrite = open(name, 'w')\n",
    "    for item in raw:\n",
    "        if item != '':\n",
    "            fwrite.write(item+'\\n')\n",
    "    fwrite.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning authors with multiple paper numbers is much more difficult but the tools required are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the files again and for identical author names, align them into one\n",
    "# single line\n",
    "for name in filename:\n",
    "    fread = open(name, 'r')\n",
    "    line1 = fread.readline()[:-1]  # skip the newline character\n",
    "    nextline = 'a'  # fill in some dummy to start while loop\n",
    "    content = ''\n",
    "    while line1 != '':  # not eof\n",
    "        nextline = fread.readline()[:-1]\n",
    "        if nextline != '':  # not eof\n",
    "            line2 = re.split(':', nextline)\n",
    "            name1 = line1.split(':')[0]\n",
    "            name2 = line2[0]\n",
    "            id2 = line2[1].split('\\n')\n",
    "            while name1 == name2:\n",
    "                line1 = line1+', '+id2[0]\n",
    "                nextline = fread.readline()[:-1]\n",
    "                line2 = re.split(':|\\n', nextline)\n",
    "                name2 = line2[0]\n",
    "                # may encounter error, to ensure the newline character removal\n",
    "                try:\n",
    "                    id2 = line2[1].split('\\n')\n",
    "                except Exception:\n",
    "                    break\n",
    "            content = content+line1+'\\n'\n",
    "        else:\n",
    "            content = content+line1+'\\n'\n",
    "        line1 = nextline\n",
    "    fread.close()\n",
    "    fwrite = open(name, 'w')\n",
    "    fwrite.write(content)\n",
    "    fwrite.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying the data into the LaTeX template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latex template is composed of two parts, the _preamble_ which we prepare beforehand, and the _document content_ which we create by Python with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move forward, let's look at the preamble part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "% document class definition\n",
      "\\documentclass[letter, 10pt, oneside]{article}\n",
      "\\setlength{\\parskip}{0in}\n",
      "\\setlength{\\parindent}{0in}\n",
      "\\textwidth = 470pt\n",
      "\\linespread{1.1}\n",
      "\\textheight = 630pt\n",
      "\\oddsidemargin = 15pt\n",
      "\\marginparsep = 4pt\n",
      "\\marginparwidth = 0pt\n",
      "\\hoffset = -0.5in\n",
      "\\footskip = 10pt\n",
      "\\pagestyle{empty}\n",
      "\\setlength{\\columnsep}{1in}\n",
      "\\columnwidth = 3in\n",
      "\n",
      "% include packages\n",
      "\\usepackage[pdftex, hidelinks]{hyperref} % for hyperlink\n",
      "\\usepackage[utf8]{inputenc}\n",
      "\\usepackage{supertabular} % for long table\n",
      "\\usepackage{array} % for left-aligned cells\n",
      "\\newcolumntype{P}[1]{>{\\raggedright\\arraybackslash}p{#1}}\n",
      "\n",
      "\\begin{document}\n",
      "\n",
      "\\twocolumn[  % for two columns\n",
      "\\begin{@twocolumnfalse}\n",
      "{\\centering{\\Large{\\bf{Author Index}}} \\\\}\n",
      "\\vspace{0.5in}\n",
      "\\end{@twocolumnfalse}\n",
      "]\n",
      "\\centering{\n",
      "\\begin{supertabular}{p{2.25in} P{1in}}\n"
     ]
    }
   ],
   "source": [
    "with open('preamble.tex') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the document content and append it to the preamble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write latex files for a table with space fill in between\n",
    "latex_filename = []\n",
    "# use UTF-8 for European characters\n",
    "preamble = str.encode(open('preamble.tex', 'r').read())\n",
    "ending = b'\\\\end{supertabular}\\n}\\n\\n\\\\end{document}'  # for the ending of the document content\n",
    "for name in filename:\n",
    "    # open file\n",
    "    latex_name = name.split('.txt')[0]+'.tex'\n",
    "    latex_filename.append(latex_name)\n",
    "    latex_write = open(latex_name, 'wb')\n",
    "\n",
    "    # write preamble and table headers stored in another tex file\n",
    "    latex_write.write(preamble+b'\\n')\n",
    "\n",
    "    fread = open(name, 'r')\n",
    "    line = re.split(':|\\n', fread.readline())\n",
    "    while line != ['']:\n",
    "        # add link to each number\n",
    "        num_string = [num.strip() for num in line[1].split(',')]\n",
    "        if num_string[0][0] == '1':\n",
    "            store = 'COMP_Links/'\n",
    "        elif num_string[0][0] == '2':\n",
    "            store = 'Refrig_LINKS/'\n",
    "        else:\n",
    "            store = 'Bldg_LINKS/'\n",
    "        pdf_string = []\n",
    "        for ind_num in num_string:\n",
    "            pdf_string.append(\n",
    "                '\\href{run:./'+store+ind_num+'.pdf}{'+ind_num+'}'\n",
    "            )\n",
    "        pdf_new = pdf_string[0]\n",
    "        if len(num_string) > 1:\n",
    "            for entry in [\n",
    "                ', '+pdf_string[i] for i in range(1,len(num_string))\n",
    "            ]:\n",
    "                pdf_new = pdf_new+entry\n",
    "        latex_write.write(\n",
    "            str.encode(line[0].replace('_', ' ')+' '+' & '+pdf_new+'\\\\\\ '+'\\n')\n",
    "        )\n",
    "        line = re.split(':|\\n', fread.readline())\n",
    "    latex_write.write(ending)\n",
    "    fread.close()\n",
    "    latex_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the '.tex' files created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "% document class definition\n",
      "\\documentclass[letter, 10pt, oneside]{article}\n",
      "\\setlength{\\parskip}{0in}\n",
      "\\setlength{\\parindent}{0in}\n",
      "\\textwidth = 470pt\n",
      "\\linespread{1.1}\n",
      "\\textheight = 630pt\n",
      "\\oddsidemargin = 15pt\n",
      "\\marginparsep = 4pt\n",
      "\\marginparwidth = 0pt\n",
      "\\hoffset = -0.5in\n",
      "\\footskip = 10pt\n",
      "\\pagestyle{empty}\n",
      "\\setlength{\\columnsep}{1in}\n",
      "\\columnwidth = 3in\n",
      "\n",
      "% include packages\n",
      "\\usepackage[pdftex, hidelinks]{hyperref} % for hyperlink\n",
      "\\usepackage[utf8]{inputenc}\n",
      "\\usepackage{supertabular} % for long table\n",
      "\\usepackage{array} % for left-aligned cells\n",
      "\\newcolumntype{P}[1]{>{\\raggedright\\arraybackslash}p{#1}}\n",
      "\n",
      "\\begin{document}\n",
      "\n",
      "\\twocolumn[  % for two columns\n",
      "\\begin{@twocolumnfalse}\n",
      "{\\centering{\\Large{\\bf{Author Index}}} \\\\}\n",
      "\\vspace{0.5in}\n",
      "\\end{@twocolumnfalse}\n",
      "]\n",
      "\\centering{\n",
      "\\begin{supertabular}{p{2.25in} P{1in}}\n",
      "Aleksandr, Drozdov   & \\href{run:./COMP_Links/1197.pdf}{1197}\\\\ \n",
      "Almbauer, Raimund   & \\href{run:./COMP_Links/1260.pdf}{1260}\\\\ \n",
      "Anami, Keiko   & \\href{run:./COMP_Links/1562.pdf}{1562}, \\href{run:./COMP_Links/1565.pdf}{1565}\\\\ \n",
      "Andreotti, Thiago   & \\href{run:./COMP_Links/1217.pdf}{1217}\\\\ \n",
      "Angadi, Shruti   & \\href{run:./COMP_Links/1146.pdf}{1146}\\\\ \n",
      "Arantes, Danilo Martins   & \\href{run:./COMP_Links/1217.pdf}{1217}\\\\ \n",
      "Arceno, Eduardo   & \\href{run:./COMP_Links/1324.pdf}{1324}\\\\ \n",
      "Arjeneh, Mohammad   & \\href{run:./COMP_Links/1353.pdf}{1353}\\\\ \n",
      "Aw, Kuan Thai   & \\href{run:./COMP_Links/1216.pdf}{1216}\\\\ \n",
      "Balide, Venkatesham   & \\href{run:./COMP_Links/1146.pdf}{1146}\\\\ \n",
      "Beinert, Michael   & \\href{run:./COMP_Links/1667.pdf}{1667}\\\\ \n"
     ]
    }
   ],
   "source": [
    "with open('author_index_raw_comp.tex') as f:\n",
    "    for i in range(45):\n",
    "        print(f.readline()[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compile the created the 3 LaTeX files for the 3 author indexes, we need a LaTeX compiler. In this demo, we'll use [MikiTeX](https://miktex.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instruction online to install the software, and we can compile the files by simply running the command\n",
    "```\n",
    "latexmk -pdf author*.tex\n",
    "```\n",
    "at the terminal/ command terminal or running the following in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('latexmk -pdf author*.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the pdf files of author indexes will be here for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
